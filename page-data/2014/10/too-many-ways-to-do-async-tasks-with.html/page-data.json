{"componentChunkName":"component---src-templates-blog-post-js","path":"/2014/10/too-many-ways-to-do-async-tasks-with.html/","result":{"data":{"site":{"siteMetadata":{"title":"Asko Soukka","author":"Asko Soukka"}},"markdownRemark":{"id":"81243aca-5fe4-5928-b802-af9b54df704a","fields":{"slug":"/2014/10/too-many-ways-to-do-async-tasks-with.html/"},"excerpt":"Triggering asynchronous tasks from Plone is hard,\nwe hear. And that’s actually quite surprising, given that, from its\nvery beginning, Plone has been running on…","html":"<p>Triggering asynchronous tasks from <a href=\"http://plone.org/\">Plone</a> is hard,\nwe hear. And that’s actually quite surprising, given that, from its\nvery beginning, Plone has been running on top of the first asynchronous\nweb server written in Python,\n<a href=\"http://www.nightmare.com/medusa/\">medusa</a>.</p>\n<p>Of course, there exist many, too many, different solutions to run\nasynchronous task with Plone:</p>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/plone.app.async\">plone.app.async</a> is\nthe only one in Plone-namespace, and probably the most criticized\none, because of using ZODB to persist its task queue</li>\n<li><a href=\"https://pypi.python.org/pypi/netsight.async\">netsight.async</a> on the\nother hand being simpler by just executing the the given task\noutside Zope worker pool (but requiring its own database\nconnection).</li>\n<li>finally, if you happen to like Celery, Nathan Van Gheem is working\non a simple Celery-integration,\n<a href=\"https://github.com/collective/collective.celery\">collective.celery</a>,\nbased on an earlier work by David Glick.</li>\n</ul>\n<p>To add insult to injury, I’ve ended up developing a more than one\nmethod more, because of, being warned about plone.app.async, being hit\nhard by the opinionated internals of Celery, being unaware of\nnetsight.async, and because single solution has not fit all my use\ncases.</p>\n<p>I believe, my various use cases can mostly be fit into these categories:</p>\n<ul>\n<li>\n<p>Executing simple tasks with unpredictable execution time so that the\nexecution cannot block all of the valuable Zope worker threads\nserving HTTP requests (amount of threads is fixed in Zope, because\nZODB connection cached cannot be shared between simultaneous\nrequests and one can afford only so much server memory per site).</p>\n<p>Examples: communicating to external services, loading an external\nRSS feed, …</p>\n</li>\n<li>\n<p>Queueing a lot of background tasks to be executed now or later,\nbecause possible results can be delivered asynchronously (e.g. user\ncan return to see it later, can get notified about finished tasks,\netc), or when it would benefit to be able to distribute the work\nbetween multiple Zope worker instances.</p>\n<p>Examples: converting files, encoding videos, burning PDFs, sending a\nlot of emails, …</p>\n</li>\n<li>\n<p>Communicating with external services.</p>\n<p>Examples: integration between sites or different systems,\nsynchronizing content between sites, performing migrations, …</p>\n</li>\n</ul>\n<p>For further reading about all the possible issues when queing\nasynchronous tasks, I’d recommend <a href=\"http://www.wiggy.net/articles/task-queues\">Whichert Akkermans’ blog post about\ntask queues</a>.</p>\n<p>So, here’s the summary, from my most simple approach solution to\nenterprise messaging with RabbitMQ:</p>\n<h2>ZPublisher stream iterator workers</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\" cm-s-solarized\"><code><span class=\"cm-keyword\">class</span><span> </span><span class=\"cm-def\">MyView</span><span>(</span><span class=\"cm-variable\">BrowserView</span><span>):</span><span>\n\n</span><span>    </span><span class=\"cm-keyword\">def</span><span> </span><span class=\"cm-def\">__call__</span><span>(</span><span class=\"cm-variable-2\">self</span><span>):</span><span>\n</span><span>        </span><span class=\"cm-keyword\">return</span><span> </span><span class=\"cm-variable\">AsyncWorkerStreamIterator</span><span>(</span><span class=\"cm-variable\">some_callable</span><span>, </span><span class=\"cm-variable-2\">self</span><span>.</span><span class=\"cm-property\">request</span><span>)</span></code></pre>\n    </div>\n<p>I’ve already blogged earlier in detail about <a href=\"http://datakurre.pandala.org/2014/05/asynchronous-stream-iterators-and.html\">how to abuse\nZPublisher’s stream iterator interface to free the current Zope worker\nthread</a>\nand process the current response outside Zope worker threads before\nletting the response to continue its way towards the requesting client\n(browser).</p>\n<p>An example of this trick is a yet another zip-export add-on\n<a href=\"https://pypi.python.org/pypi/collective.jazzport\">collective.jazzport</a>.\nIt exports Plone-folders as zip-files by downloading all those\nto-be-zipped files separately simply through ZPublisher (or, actually,\nusing site’s public address). It can also download files in parallel to\nuse all the available load balanced instances. Yet, because it downloads\nfiles only after freeing the current Zope worker instance, it should not\nblock any worker thread by itself (see its\n<a href=\"https://github.com/datakurre/collective.jazzport/blob/master/src/collective/jazzport/browser.py\">browser.py</a>,\nand\n<a href=\"https://github.com/datakurre/collective.jazzport/blob/master/src/collective/jazzport/iterators.py\">iterators.py</a>).</p>\n<p>There are two major limitations for this approach (common to all\nZPublisher stream iterators):</p>\n<ul>\n<li>The code should not access ZODB after the worker thread has been\nfreed (unless a completely new connection with new cache is\ncreated).</li>\n<li>This does not help installations with HAProxy or similar front-end\nproxy with fixed allowed simultaneous requests per Zope instance.</li>\n</ul>\n<p>Also, of course, this is not real async, because it keeps the client\nwaiting until the request is completed and cannot distribute work\nbetween Zope instances.</p>\n<h2><a href=\"https://pypi.python.org/pypi/collective.futures\">collective.futures</a></h2>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\" cm-s-solarized\"><code><span class=\"cm-keyword\">class</span><span> </span><span class=\"cm-def\">MyView</span><span>(</span><span class=\"cm-variable\">BrowserView</span><span>):</span><span>\n\n</span><span>    </span><span class=\"cm-keyword\">def</span><span> </span><span class=\"cm-def\">__call__</span><span>(</span><span class=\"cm-variable-2\">self</span><span>):</span><span>\n</span><span>        </span><span class=\"cm-keyword\">try</span><span>:</span><span>\n</span><span>            </span><span class=\"cm-keyword\">return</span><span> </span><span class=\"cm-variable\">futures</span><span>.</span><span class=\"cm-property\">result</span><span>(</span><span class=\"cm-string\">'my_unique_key'</span><span>)</span><span>\n</span><span>        </span><span class=\"cm-keyword\">except</span><span> </span><span class=\"cm-variable\">futures</span><span>.</span><span class=\"cm-property\">FutureNotSubmittedError</span><span>:</span><span>\n</span><span>            </span><span class=\"cm-variable\">futures</span><span>.</span><span class=\"cm-property\">submit</span><span>(</span><span class=\"cm-string\">'my_unique_key'</span><span>, </span><span class=\"cm-variable\">some_callable</span><span>, </span><span class=\"cm-string\">'foo'</span><span>, </span><span class=\"cm-string\">'bar'</span><span>)</span><span>\n</span><span>            </span><span class=\"cm-keyword\">return</span><span> </span><span class=\"cm-string\">u'A placeholder value, which is never really returned.'</span></code></pre>\n    </div>\n<p><strong>collective.futures</strong> was the next step from the previous approach. It\nprovides a simple API for registering multiple tasks (which does not\nneed to access ZODB) so that they will be executed outside the current\nZope worker thread.</p>\n<p>Once all the registered tasks have been executed, the same request will\nbe queued for ZPublisher to be processed again, now with the responses\nfrom those registered tasks.</p>\n<p>Finally, the response will be returned for the requesting like with any\nother requests.</p>\n<p><strong>collective.futures</strong> has the same issues as the previous approach\n(used in\n<a href=\"https://pypi.python.org/pypi/collective.jazzport\">collective.jazzport</a>),\nand it may also waste resources by processing certain parts of the\nrequest twice (like publish traverse).</p>\n<p>We use this, for example, for loading external RSS feeds so that the\nZope worker threads are freed to process other requests while we are\nwaiting the external services to return us those feeds.</p>\n<h2><a href=\"https://pypi.python.org/pypi/collective.taskqueue\">collective.taskqueue</a></h2>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\" cm-s-solarized\"><code><span class=\"cm-keyword\">class</span><span> </span><span class=\"cm-def\">MyView</span><span>(</span><span class=\"cm-variable\">BrowserView</span><span>):</span><span>\n\n</span><span>    </span><span class=\"cm-keyword\">def</span><span> </span><span class=\"cm-def\">__call__</span><span>(</span><span class=\"cm-variable-2\">self</span><span>):</span><span>\n</span><span>        </span><span class=\"cm-variable\">taskqueue</span><span>.</span><span class=\"cm-property\">add</span><span>(</span><span class=\"cm-string\">'/Plone/path/to/some/other/view'</span><span>)</span><span>\n</span><span>        </span><span class=\"cm-keyword\">return</span><span> </span><span class=\"cm-string\">u'Task queued, and a better view could now display a throbber.'</span></code></pre>\n    </div>\n<p><strong>collective.taskqueue</strong> should be a real alternative for\n<a href=\"https://pypi.python.org/pypi/plone.app.async\">plone.app.async</a> and\n<a href=\"https://pypi.python.org/pypi/netsight.async\">netsight.async</a>. I see it\nas a simple and opinionated sibling of\n<a href=\"https://pypi.python.org/pypi/collective.zamqp\">collective.zamqp</a>, and\nit should be able to handle all the most basic asynchrnous tasks where\nno other systems are involved.</p>\n<p><strong>collective.taskqueue</strong> provides one or more named asynchronously\nconsumed task queues, which may contain any number of tasks:\nasynchronously dispatched simple requests to any traversable resources\nin Plone.</p>\n<p>With out-of-the-box Plone (without any other add-ons or external\nservices) it provides instance local volatile memory based task queues,\nwhich are consumed by the other one of the default two Zope worker\nthreads. With <a href=\"http://redis.io/\">redis</a>, it supports persistent task\nqueues with quaranteed delivery and distributed consumption. For\nexample, you could have dedicated Plone instances to only consume those\nshared task queues from Redis.</p>\n<p>To not sound too good to be true, <strong>collective.taskqueue</strong> does not have\nany nind of monitoring of the task queues out-of-the-box (only a\ninstance-Z2.log entry with resulted status code for each consumed task\nis generated).</p>\n<h2><a href=\"https://pypi.python.org/pypi/collective.zamqp\">collective.zamqp</a></h2>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\" cm-s-solarized\"><code><span class=\"cm-keyword\">class</span><span> </span><span class=\"cm-def\">MyView</span><span>(</span><span class=\"cm-variable\">BrowserView</span><span>):</span><span>\n\n</span><span>    </span><span class=\"cm-keyword\">def</span><span> </span><span class=\"cm-def\">__call__</span><span>(</span><span class=\"cm-variable-2\">self</span><span>):</span><span>\n</span><span>        </span><span class=\"cm-variable\">producer</span><span> </span><span class=\"cm-operator\">=</span><span> </span><span class=\"cm-variable\">getUtility</span><span>(</span><span class=\"cm-variable\">IProducer</span><span>, </span><span class=\"cm-variable\">name</span><span class=\"cm-operator\">=</span><span class=\"cm-string\">'my.asyncservice'</span><span>)</span><span>\n</span><span>        </span><span class=\"cm-variable\">producer</span><span>.</span><span class=\"cm-property\">register</span><span>()  </span><span class=\"cm-comment\"># bind to successful transaction</span><span>\n</span><span>        </span><span class=\"cm-variable\">producer</span><span>.</span><span class=\"cm-property\">publish</span><span>({</span><span class=\"cm-string\">'title'</span><span>: </span><span class=\"cm-string\">u'My title'</span><span>})</span><span>\n</span><span>        </span><span class=\"cm-keyword\">return</span><span> </span><span class=\"cm-string\">u'Task queued, and a better view could now display a throbber.'</span></code></pre>\n    </div>\n<p>Finally, <strong>collective.zamqp</strong> is a very flexible asynchronous framework\nand <a href=\"http://www.rabbitmq.com/\">RabbitMQ</a> integration for Plone, which I\nre-wrote from\n<a href=\"https://pypi.python.org/pypi/affinitic.zamqp\">affinitic.zamqp</a> before\nfiguring out any of the previous approaches.</p>\n<p>As the story behind it goes, we did use <strong>affinitic.zamqp</strong> at first,\nbut because of its issues we had to start rewrite to make it more stable\nand compatible with newer AMQP specifications. At first, I tried to\nbuilt it on top of Celery, then on top of Kombu (transport framework\nbehind Celery), but at the end it had to be based directly on top of\n<a href=\"https://pypi.python.org/pypi/pika\">pika</a> (0.9.4), a popular Python AMQP\nlibrary. Otherwise it would have been really difficult to benefit from\nall the possible features of RabbitMQ and be compatible with other that\nPython based services.</p>\n<p><strong>collective.zamqp</strong> is best used for configuring and executing\nasynchronous messaging between Plone sites, other Plone sites and other\nAMQP-connected services. It’s also possible to use it to build frontend\nmessaging services (possibly secured using SSL) with RabbitMQ’s\nwebstomp server (see the\n<a href=\"https://github.com/datakurre/chatbehavior\">chatbehavior</a>-example). Yet,\nit has a few problems of its own:</p>\n<ul>\n<li>it depends on five.grok</li>\n<li>it’s way too tighly integrated with pika 0.9.5, which makes\nupgrading the integration more difficult than necessary (and pika\n0.9.5 has a few serious bugs related to synchronous AMQP\nconnections, luckily not requird for c.zamqp)</li>\n<li>it has a quite bit of poorly documented magic in how to use it to\nmake all the possible AMQP messaging configurations.</li>\n</ul>\n<p><strong>collective.zamqp</strong> does not provide monitoring utilities of its own\n(beyond very detailed logging of messaging events). Yet, the basic\nmonitoring needs can be covered with RabbitMQ’s web and console UIs and\nRESTful APIs, and all decent monitoring tools should have their own\nRabbitMQ plugins.</p>\n<p>For more detailed examples of <strong>collective.zamqp</strong>, please, see <a href=\"http://stackoverflow.com/questions/24636315/using-rabbitmq-with-plone-celery-or-not\">my\nrelated StackOverflow\nanswer</a>\nand <a href=\"http://www.slideshare.net/datakurre/plone-rabbit-mq-and-messaging-that-just-works\">our presentation from PloneConf\n2012</a>\n(more examples are linked from the last slide).</p>","frontmatter":{"title":"Too many ways to do async tasks with Plone","tags":["Async","Asyncore","Medusa","Plone","RabbitMQ"],"date":"October 23, 2014","published":"2014-10-23 06:00:00"}}},"pageContext":{"slug":"/2014/10/too-many-ways-to-do-async-tasks-with.html/","previous":{"fields":{"slug":"/2014/09/nix-expressions-as-executable-commands.html/"},"frontmatter":{"title":"Nix expressions as executable commands"}},"next":{"fields":{"slug":"/2014/11/transmogrifier-python-migration.html/"},"frontmatter":{"title":"Transmogrifier, the Python migration pipeline, also for Python 3"}}}},"staticQueryHashes":["63159454"],"slicesMap":{}}